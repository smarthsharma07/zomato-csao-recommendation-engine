# Scalability Considerations

To ensure the recommendation system can handle millions of daily prediction requests at Zomato's scale, we prioritized low-latency architectural decisions:

## 1. Latency Optimization (< 300ms SLA)
- **Measured Inference:** Our offline evaluation pipeline clocked an average end-to-end inference latency of ~40ms per request. This easily satisfies the stringent < 300ms SLA requirement for real-time cart prediction.
- **Precomputed Item Embeddings:** To guarantee this speed despite using transformer models for embeddings, **all catalog item embeddings are precomputed offline**. At runtime, we only embed and mean-pool the active cart items.
- **Two-Stage Funneling:** By using the Vector Embedding graph as a "first pass" retrieval mechanism to fetch candidates out of a massive global catalog linearly, we prevent the heavy LightGBM Machine Learning ranker from running excessive evaluations on irrelevant items.

## 2. Model Size and Overhead
- **`all-MiniLM-L6-v2`:** We specifically chose this sentence-transformer model because it is incredibly lightweight ($~90$ MB footprint) while perfectly adequate for semantic mapping of food terminology. Memory loading issues on containerized worker nodes are virtually non-existent.
- **LightGBM:** This framework is notoriously efficient, storing decision trees in integer-mapped leaf structures rather than bloated floating-point memory, minimizing cold-start spin-up times for the API endpoint.

## 3. Pre-Deployment Benchmarking Strategy
- **Load Testing Tool:** Before migrating to production, the Python API (`inference.py`) will be wrapped in a FastAPI endpoint and load-tested using **Locust**, an open-source load-testing framework.
- **Simulated Load:** We will spin up distributed Locust worker nodes to simulate 10,000 Concurrent Users (CCUs) hitting the recommendation endpoint during a mock "Friday Evening Dinner Rush."
- **Success Criteria:** The benchmark must prove that the p99 response time remains under the strict 300ms SLA, and that horizontal Node.js pod auto-scaling accurately triggers when CPU utilization breaches 75%.

## 4. Data Freshness
- The training pipeline script (`generate_synthetic_data.py`) generates a temporal split of behavior over a rolling 90-day window. The LightGBM feature weights are designed to be efficiently retrained on weekly cron-jobs to consistently learn new shifting culinary trends over time.

## 5. Enterprise Infrastructure Scale (Millions of Items)
While the MVP logic relies on an in-memory `cosine_similarity` sweep across 300 items, this is substituted for robust enterprise infrastructure at Zomato scale:
- **Vector Databases (FAISS / Milvus):** The Stage-1 retrieval sweep is transitioned into an Approximate Nearest Neighbors (ANN) clustered search. This enables the Stage-1 embedding sweep to evaluate 1,000,000+ items and return the 50 candidates in < 10ms.
- **Centralized Feature Stores (Redis):** Calculating rolling window features (e.g., User Veg Ratio) on the fly represents unnecessary block-time. In production, these features are asynchronously computed nightly by Spark pipelines and loaded into an ultra-fast Redis Feature Store. The live endpoint simply pulls `redis.get(user_id_features)` instantly when constructing the LightGBM input array.
- **Asynchronous Embeddings:** Distilling new menu item text-descriptions into `all-MiniLM-L6-v2` dense 384d vectors is executed asynchronously off the main thread by background workers when restaurants update their menus.
